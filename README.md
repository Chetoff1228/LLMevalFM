# LLMevalFM
LLMevalFM: Оценка Качества Социополитических Моделей

LLMevalFM - это бенчмарк, разработанный для оценки фактической точности больших языковых моделей (LLM), конкретно в русском контексте.

Большие языковые модели (LLM) всё чаще применяются в самых различных областях благодаря своим развивающимся возможностям в задачах обработки естественного языка. Однако внедрение LLM в системы, где ошибки могут иметь негативные последствия, требует тщательной проверки их надежности. Особенно важно оценивать фактическую точность LLM, чтобы определить, насколько хорошо сгенерированный текст соответствует реальным фактам. Несмотря на наличие множества фактических бенчмарков, лишь малая часть оценивает знания моделей в русском контексте. Более того, эти бенчмарки часто обходят стороной спорные и чувствительные темы, несмотря на то, что Россия имеет определенные позиции по таким вопросам.

Для решения этой проблемы мы разработали бенчмарк LLMevalFM, который состоит примерно из 14,000 чувствительных вопросов, относящихся к российскому контексту в различных областях знания. Для каждого вопроса мы также измерили фактор провокации, который оценивает чувствительность респондента к теме. Результаты бенчмарка позволили нам ранжировать многоязычные LLM на основе их ответов на значимые темы, такие как история, политические науки, социология, политическая география и основы национальной безопасности.

Мы надеемся, что наше исследование привлечёт внимание к этой проблеме и станет толчком для разработки новых фактических бенчмарков. Оценивая качество LLM, мы стремимся внести вклад в гармонизацию информационного пространства, доступного для широкого круга пользователей.

Ключевые изменения: вычисления качества LLM с использованием данных.
